{"decls":{"FairnessLearning.Action":[58,0,61,31,61,4,61,10],"FairnessLearning.AdaptiveParams":[327,0,336,24,330,10,330,24],"FairnessLearning.BanditAlgorithm":[212,0,215,65,215,4,215,19],"FairnessLearning.BanditFeedback":[203,0,210,21,206,10,206,24],"FairnessLearning.Constraint":[257,0,260,41,260,4,260,14],"FairnessLearning.ExpWeightsParams":[138,0,145,15,141,10,141,26],"FairnessLearning.LearningReport":[347,0,358,25,348,10,348,24],"FairnessLearning.Loss":[63,0,66,16,66,7,66,11],"FairnessLearning.MultiObjective":[302,0,309,50,305,10,305,24],"FairnessLearning.OnlineAlgorithm":[77,0,80,64,80,4,80,19],"FairnessLearning.OnlineProblem":[68,0,75,47,71,10,71,23],"FairnessLearning.StochasticProblem":[233,0,240,19,236,10,236,27],"FairnessLearning.TimeHorizon":[53,0,56,20,56,4,56,15],"FairnessLearning.adagradLearningRate":[338,0,343,50,342,4,342,23],"FairnessLearning.averageRegret":[120,0,124,38,123,4,123,17],"FairnessLearning.bestFixedLoss":[98,0,104,3,101,4,101,17],"FairnessLearning.budgetConstraint":[262,0,266,30,265,4,265,20],"FairnessLearning.constrainedRegret":[274,0,278,28,277,4,277,21],"FairnessLearning.cumulativeLoss":[92,0,96,12,95,4,95,18],"FairnessLearning.epsilonGreedy":[224,0,229,45,227,4,227,17],"FairnessLearning.expWeightsUpdate":[147,0,152,48,150,4,150,20],"FairnessLearning.explorationRate":[217,0,222,34,221,4,221,19],"FairnessLearning.fairRegret":[178,0,183,23,181,4,181,14],"FairnessLearning.fair_regret_nonneg":[185,0,199,48,188,8,188,26],"FairnessLearning.fairnessConstraint":[268,0,272,37,271,4,271,22],"FairnessLearning.fairnessLoss":[156,0,160,38,159,4,159,16],"FairnessLearning.fairnessOnlineProblem":[171,0,176,53,174,4,174,25],"FairnessLearning.fairness_loss_bounded":[162,0,169,56,168,6,168,27],"FairnessLearning.followTheLeader":[128,0,136,22,131,4,131,19],"FairnessLearning.generateLearningReport":[360,0,375,3,361,4,361,26],"FairnessLearning.learning_product":[379,0,400,72,391,8,391,24],"FairnessLearning.novelty_claim_learning":[402,0,419,9,416,8,416,30],"FairnessLearning.optimalStochasticAction":[242,0,247,16,245,4,245,27],"FairnessLearning.paretoRegret":[311,0,316,65,314,4,314,16],"FairnessLearning.projectOntoFeasible":[280,0,286,45,283,4,283,23],"FairnessLearning.projected_maintains_feasibility":[288,0,298,11,291,8,291,39],"FairnessLearning.pseudoRegret":[249,0,253,45,252,4,252,16],"FairnessLearning.regret":[106,0,110,20,109,4,109,10],"FairnessLearning.regret_nonneg":[112,0,118,10,115,8,115,21],"FairnessLearning.runAlgorithm":[82,0,88,4,85,4,85,16],"FairnessLearning.scalarizedLoss":[318,0,323,40,321,4,321,18]},"directImports":[["Perspective.FairnessGames",false,false,false]],"module":"Perspective.FairnessLearning","references":{"{\"c\":{\"m\":\"Init.Data.List.Basic\",\"n\":\"List.sum\"}}":{"definition":null,"usages":[[96,9,96,12,"FairnessLearning.cumulativeLoss"]]},"{\"c\":{\"m\":\"Init.Data.List.Lemmas\",\"n\":\"List.mem_map\"}}":{"definition":null,"usages":[[193,6,193,18,"FairnessLearning.fair_regret_nonneg"]]},"{\"c\":{\"m\":\"Init.Data.NeZero\",\"n\":\"NeZero\"}}":{"definition":null,"usages":[[159,18,159,24,"FairnessLearning.fairnessLoss"],[168,29,168,35,"FairnessLearning.fairness_loss_bounded"],[174,27,174,33,"FairnessLearning.fairnessOnlineProblem"],[181,16,181,22,"FairnessLearning.fairRegret"],[188,28,188,34,"FairnessLearning.fair_regret_nonneg"],[271,24,271,30,"FairnessLearning.fairnessConstraint"],[391,26,391,32,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Init.Data.Rat.Basic\",\"n\":\"Rat\"}}":{"definition":null,"usages":[[61,30,61,31,"FairnessLearning.Action"],[66,15,66,16,"FairnessLearning.Loss"],[95,42,95,43,"FairnessLearning.cumulativeLoss"],[101,55,101,56,"FairnessLearning.bestFixedLoss"],[109,22,109,23,"FairnessLearning.regret"],[109,37,109,38,"FairnessLearning.regret"],[109,42,109,43,"FairnessLearning.regret"],[115,42,115,43,"FairnessLearning.regret_nonneg"],[123,33,123,34,"FairnessLearning.averageRegret"],[123,46,123,47,"FairnessLearning.averageRegret"],[143,6,143,7,"FairnessLearning.ExpWeightsParams"],[150,76,150,77,"FairnessLearning.expWeightsUpdate"],[151,22,151,23,"FairnessLearning.expWeightsUpdate"],[151,35,151,36,"FairnessLearning.expWeightsUpdate"],[159,52,159,53,"FairnessLearning.fairnessLoss"],[168,63,168,64,"FairnessLearning.fairness_loss_bounded"],[174,54,174,55,"FairnessLearning.fairnessOnlineProblem"],[181,67,181,68,"FairnessLearning.fairRegret"],[181,72,181,73,"FairnessLearning.fairRegret"],[188,79,188,80,"FairnessLearning.fair_regret_nonneg"],[198,14,198,15,"FairnessLearning.fair_regret_nonneg"],[221,30,221,31,"FairnessLearning.explorationRate"],[222,32,222,33,"FairnessLearning.explorationRate"],[227,23,227,24,"FairnessLearning.epsilonGreedy"],[238,28,238,29,"FairnessLearning.StochasticProblem"],[240,18,240,19,"FairnessLearning.StochasticProblem"],[252,56,252,57,"FairnessLearning.pseudoRegret"],[252,69,252,70,"FairnessLearning.pseudoRegret"],[265,31,265,32,"FairnessLearning.budgetConstraint"],[271,43,271,44,"FairnessLearning.fairnessConstraint"],[271,51,271,52,"FairnessLearning.fairnessConstraint"],[277,50,277,51,"FairnessLearning.constrainedRegret"],[277,55,277,56,"FairnessLearning.constrainedRegret"],[309,49,309,50,"FairnessLearning.MultiObjective"],[315,28,315,29,"FairnessLearning.paretoRegret"],[321,79,321,80,"FairnessLearning.scalarizedLoss"],[322,21,322,22,"FairnessLearning.scalarizedLoss"],[332,7,332,8,"FairnessLearning.AdaptiveParams"],[334,6,334,7,"FairnessLearning.AdaptiveParams"],[342,73,342,74,"FairnessLearning.adagradLearningRate"],[342,78,342,79,"FairnessLearning.adagradLearningRate"],[352,21,352,22,"FairnessLearning.LearningReport"],[354,18,354,19,"FairnessLearning.LearningReport"],[361,53,361,54,"FairnessLearning.generateLearningReport"],[364,43,364,44,"FairnessLearning.generateLearningReport"],[391,77,391,78,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Init.Prelude\",\"n\":\"Bool\"}}":{"definition":null,"usages":[[228,15,228,19,"FairnessLearning.epsilonGreedy"],[356,16,356,20,"FairnessLearning.LearningReport"]]},"{\"c\":{\"m\":\"Init.Prelude\",\"n\":\"DecidablePred\"}}":{"definition":null,"usages":[[284,5,284,18,"FairnessLearning.projectOntoFeasible"],[292,5,292,18,"FairnessLearning.projected_maintains_feasibility"],[394,38,394,51,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Init.Prelude\",\"n\":\"Fin\"}}":{"definition":null,"usages":[[61,22,61,25,"FairnessLearning.Action"],[73,9,73,12,"FairnessLearning.OnlineProblem"],[150,68,150,71,"FairnessLearning.expWeightsUpdate"],[151,14,151,17,"FairnessLearning.expWeightsUpdate"],[151,27,151,30,"FairnessLearning.expWeightsUpdate"],[309,18,309,21,"FairnessLearning.MultiObjective"],[315,4,315,7,"FairnessLearning.paretoRegret"],[321,55,321,58,"FairnessLearning.scalarizedLoss"]]},"{\"c\":{\"m\":\"Init.Prelude\",\"n\":\"List\"}}":{"definition":null,"usages":[[80,31,80,35,"FairnessLearning.OnlineAlgorithm"],[86,4,86,8,"FairnessLearning.runAlgorithm"],[95,29,95,33,"FairnessLearning.cumulativeLoss"],[131,31,131,35,"FairnessLearning.followTheLeader"],[181,41,181,45,"FairnessLearning.fairRegret"],[188,53,188,57,"FairnessLearning.fair_regret_nonneg"],[215,31,215,35,"FairnessLearning.BanditAlgorithm"],[314,57,314,61,"FairnessLearning.paretoRegret"],[391,51,391,55,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Init.Prelude\",\"n\":\"List.map\"}}":{"definition":null,"usages":[[182,28,182,31,"FairnessLearning.fairRegret"],[316,39,316,42,"FairnessLearning.paretoRegret"]]},"{\"c\":{\"m\":\"Init.Prelude\",\"n\":\"Max.max\"}}":{"definition":null,"usages":[[160,27,160,30,"FairnessLearning.fairnessLoss"],[199,13,199,16,"FairnessLearning.fair_regret_nonneg"]]},"{\"c\":{\"m\":\"Init.Prelude\",\"n\":\"Nat\"}}":{"definition":null,"usages":[[49,14,49,15],[56,19,56,20,"FairnessLearning.TimeHorizon"],[61,16,61,17,"FairnessLearning.Action"],[71,29,71,30,"FairnessLearning.OnlineProblem"],[71,37,71,38,"FairnessLearning.OnlineProblem"],[80,25,80,26,"FairnessLearning.OnlineAlgorithm"],[85,22,85,23,"FairnessLearning.runAlgorithm"],[101,23,101,24,"FairnessLearning.bestFixedLoss"],[123,41,123,42,"FairnessLearning.averageRegret"],[150,26,150,27,"FairnessLearning.expWeightsUpdate"],[174,42,174,43,"FairnessLearning.fairnessOnlineProblem"],[206,30,206,31,"FairnessLearning.BanditFeedback"],[215,25,215,26,"FairnessLearning.BanditAlgorithm"],[221,25,221,26,"FairnessLearning.explorationRate"],[236,33,236,34,"FairnessLearning.StochasticProblem"],[252,64,252,65,"FairnessLearning.pseudoRegret"],[260,20,260,21,"FairnessLearning.Constraint"],[305,30,305,31,"FairnessLearning.MultiObjective"],[307,18,307,19,"FairnessLearning.MultiObjective"],[350,11,350,12,"FairnessLearning.LearningReport"],[361,37,361,38,"FairnessLearning.generateLearningReport"]]},"{\"c\":{\"m\":\"Init.Prelude\",\"n\":\"String\"}}":{"definition":null,"usages":[[358,19,358,25,"FairnessLearning.LearningReport"]]},"{\"c\":{\"m\":\"Init.Prelude\",\"n\":\"True\"}}":{"definition":null,"usages":[[418,4,418,8,"FairnessLearning.novelty_claim_learning"]]},"{\"c\":{\"m\":\"Mathlib.Algebra.Order.BigOperators.Group.List\",\"n\":\"List.sum_nonneg\"}}":{"definition":null,"usages":[[191,8,191,23,"FairnessLearning.fair_regret_nonneg"]]},"{\"c\":{\"m\":\"Mathlib.Algebra.Order.GroupWithZero.Unbundled.Basic\",\"n\":\"div_nonneg\"}}":{"definition":null,"usages":[[196,8,196,18,"FairnessLearning.fair_regret_nonneg"]]},"{\"c\":{\"m\":\"Mathlib.Order.Defs.LinearOrder\",\"n\":\"le_max_right\"}}":{"definition":null,"usages":[[199,28,199,40,"FairnessLearning.fair_regret_nonneg"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.Action\"}}":{"definition":[61,4,61,10],"usages":[[73,17,73,23,"FairnessLearning.OnlineProblem"],[80,37,80,43,"FairnessLearning.OnlineAlgorithm"],[80,56,80,62,"FairnessLearning.OnlineAlgorithm"],[86,10,86,16,"FairnessLearning.runAlgorithm"],[131,37,131,43,"FairnessLearning.followTheLeader"],[131,72,131,78,"FairnessLearning.followTheLeader"],[131,84,131,90,"FairnessLearning.followTheLeader"],[159,33,159,39,"FairnessLearning.fairnessLoss"],[168,44,168,50,"FairnessLearning.fairness_loss_bounded"],[181,47,181,53,"FairnessLearning.fairRegret"],[188,59,188,65,"FairnessLearning.fair_regret_nonneg"],[208,11,208,17,"FairnessLearning.BanditFeedback"],[215,57,215,63,"FairnessLearning.BanditAlgorithm"],[227,39,227,45,"FairnessLearning.epsilonGreedy"],[227,65,227,71,"FairnessLearning.epsilonGreedy"],[228,23,228,29,"FairnessLearning.epsilonGreedy"],[238,17,238,23,"FairnessLearning.StochasticProblem"],[245,59,245,65,"FairnessLearning.optimalStochasticAction"],[260,26,260,32,"FairnessLearning.Constraint"],[283,29,283,35,"FairnessLearning.projectOntoFeasible"],[285,23,285,29,"FairnessLearning.projectOntoFeasible"],[285,35,285,41,"FairnessLearning.projectOntoFeasible"],[291,45,291,51,"FairnessLearning.projected_maintains_feasibility"],[293,23,293,29,"FairnessLearning.projected_maintains_feasibility"],[309,38,309,44,"FairnessLearning.MultiObjective"],[314,63,314,69,"FairnessLearning.paretoRegret"],[322,9,322,15,"FairnessLearning.scalarizedLoss"],[391,57,391,63,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.AdaptiveParams\"}}":{"definition":[330,10,330,24,"FairnessLearning.AdaptiveParams"],"usages":[[342,34,342,48,"FairnessLearning.adagradLearningRate"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.AdaptiveParams.valid\"}}":{"definition":[336,2,336,7],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.AdaptiveParams.α\"}}":{"definition":[334,2,334,3],"usages":[[343,26,343,27,"FairnessLearning.adagradLearningRate"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.AdaptiveParams.η₀\"}}":{"definition":[332,2,332,4],"usages":[[343,9,343,11,"FairnessLearning.adagradLearningRate"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.BanditAlgorithm\"}}":{"definition":[215,4,215,19],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.BanditFeedback\"}}":{"definition":[206,10,206,24,"FairnessLearning.BanditFeedback"],"usages":[[215,37,215,51,"FairnessLearning.BanditAlgorithm"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.BanditFeedback.action\"}}":{"definition":[208,2,208,8],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.BanditFeedback.observedLoss\"}}":{"definition":[210,2,210,14],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.Constraint\"}}":{"definition":[260,4,260,14],"usages":[[265,36,265,46,"FairnessLearning.budgetConstraint"],[271,56,271,66,"FairnessLearning.fairnessConstraint"],[283,53,283,63,"FairnessLearning.projectOntoFeasible"],[291,69,291,79,"FairnessLearning.projected_maintains_feasibility"],[394,23,394,33,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.ExpWeightsParams\"}}":{"definition":[141,10,141,26,"FairnessLearning.ExpWeightsParams"],"usages":[[150,39,150,55,"FairnessLearning.expWeightsUpdate"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.ExpWeightsParams.η\"}}":{"definition":[143,2,143,3],"usages":[[152,35,152,36,"FairnessLearning.expWeightsUpdate"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.ExpWeightsParams.η_pos\"}}":{"definition":[145,2,145,7],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.LearningReport\"}}":{"definition":[348,10,348,24,"FairnessLearning.LearningReport"],"usages":[[361,58,361,72,"FairnessLearning.generateLearningReport"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.LearningReport.averageRegret\"}}":{"definition":[354,2,354,15],"usages":[[372,4,372,17,"FairnessLearning.generateLearningReport"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.LearningReport.cumulativeRegret\"}}":{"definition":[352,2,352,18],"usages":[[371,4,371,20,"FairnessLearning.generateLearningReport"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.LearningReport.isSublinear\"}}":{"definition":[356,2,356,13],"usages":[[373,4,373,15,"FairnessLearning.generateLearningReport"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.LearningReport.recommendation\"}}":{"definition":[358,2,358,16],"usages":[[374,4,374,18,"FairnessLearning.generateLearningReport"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.LearningReport.rounds\"}}":{"definition":[350,2,350,8],"usages":[[370,4,370,10,"FairnessLearning.generateLearningReport"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.Loss\"}}":{"definition":[66,7,66,11],"usages":[[73,28,73,32,"FairnessLearning.OnlineProblem"],[80,48,80,52,"FairnessLearning.OnlineAlgorithm"],[86,21,86,25,"FairnessLearning.runAlgorithm"],[95,34,95,38,"FairnessLearning.cumulativeLoss"],[131,48,131,52,"FairnessLearning.followTheLeader"],[159,57,159,61,"FairnessLearning.fairnessLoss"],[210,17,210,21,"FairnessLearning.BanditFeedback"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.MultiObjective\"}}":{"definition":[305,10,305,24,"FairnessLearning.MultiObjective"],"usages":[[314,24,314,38,"FairnessLearning.paretoRegret"],[321,26,321,40,"FairnessLearning.scalarizedLoss"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.MultiObjective.numObjectives\"}}":{"definition":[307,2,307,15],"usages":[[315,12,315,25,"FairnessLearning.paretoRegret"],[321,63,321,76,"FairnessLearning.scalarizedLoss"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.MultiObjective.objectiveLoss\"}}":{"definition":[309,2,309,15],"usages":[[316,48,316,61,"FairnessLearning.paretoRegret"],[323,23,323,36,"FairnessLearning.scalarizedLoss"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.OnlineAlgorithm\"}}":{"definition":[80,4,80,19],"usages":[[85,32,85,47,"FairnessLearning.runAlgorithm"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.OnlineProblem\"}}":{"definition":[71,10,71,23,"FairnessLearning.OnlineProblem"],"usages":[[85,59,85,72,"FairnessLearning.runAlgorithm"],[101,34,101,47,"FairnessLearning.bestFixedLoss"],[174,59,174,72,"FairnessLearning.fairnessOnlineProblem"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.OnlineProblem.bounded\"}}":{"definition":[75,2,75,9],"usages":[[176,2,176,9,"FairnessLearning.fairnessOnlineProblem"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.OnlineProblem.loss\"}}":{"definition":[73,2,73,6],"usages":[[175,2,175,6,"FairnessLearning.fairnessOnlineProblem"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.StochasticProblem\"}}":{"definition":[236,10,236,27,"FairnessLearning.StochasticProblem"],"usages":[[245,36,245,53,"FairnessLearning.optimalStochasticAction"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.StochasticProblem.expectedLoss\"}}":{"definition":[238,2,238,14],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.StochasticProblem.varianceBound\"}}":{"definition":[240,2,240,15],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.TimeHorizon\"}}":{"definition":[56,4,56,15],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.adagradLearningRate\"}}":{"definition":[342,4,342,23],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.averageRegret\"}}":{"definition":[123,4,123,17],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.bestFixedLoss\"}}":{"definition":[101,4,101,17],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.budgetConstraint\"}}":{"definition":[265,4,265,20],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.constrainedRegret\"}}":{"definition":[277,4,277,21],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.cumulativeLoss\"}}":{"definition":[95,4,95,18],"usages":[[183,2,183,16,"FairnessLearning.fairRegret"],[190,20,190,34,"FairnessLearning.fair_regret_nonneg"],[316,11,316,25,"FairnessLearning.paretoRegret"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.epsilonGreedy\"}}":{"definition":[227,4,227,17],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.expWeightsUpdate\"}}":{"definition":[150,4,150,20],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.explorationRate\"}}":{"definition":[221,4,221,19],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.fairRegret\"}}":{"definition":[181,4,181,14],"usages":[[189,4,189,14,"FairnessLearning.fair_regret_nonneg"],[190,9,190,19,"FairnessLearning.fair_regret_nonneg"],[393,5,393,15,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.fair_regret_nonneg\"}}":{"definition":[188,8,188,26],"usages":[[398,10,398,28,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.fairnessConstraint\"}}":{"definition":[271,4,271,22],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.fairnessLoss\"}}":{"definition":[159,4,159,16],"usages":[[169,9,169,21,"FairnessLearning.fairness_loss_bounded"],[169,32,169,44,"FairnessLearning.fairness_loss_bounded"],[175,21,175,33,"FairnessLearning.fairnessOnlineProblem"],[182,42,182,54,"FairnessLearning.fairRegret"],[195,9,195,21,"FairnessLearning.fair_regret_nonneg"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.fairnessOnlineProblem\"}}":{"definition":[174,4,174,25],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.fairness_loss_bounded\"}}":{"definition":[168,6,168,27,"FairnessLearning.fairness_loss_bounded"],"usages":[[176,24,176,45,"FairnessLearning.fairnessOnlineProblem"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.followTheLeader\"}}":{"definition":[131,4,131,19],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.generateLearningReport\"}}":{"definition":[361,4,361,26],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.learning_product\"}}":{"definition":[391,8,391,24],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.novelty_claim_learning\"}}":{"definition":[416,8,416,30],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.optimalStochasticAction\"}}":{"definition":[245,4,245,27],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.paretoRegret\"}}":{"definition":[314,4,314,16],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.projectOntoFeasible\"}}":{"definition":[283,4,283,23],"usages":[[294,16,294,35,"FairnessLearning.projected_maintains_feasibility"],[295,9,295,28,"FairnessLearning.projected_maintains_feasibility"],[396,18,396,37,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.projected_maintains_feasibility\"}}":{"definition":[291,8,291,39],"usages":[[400,10,400,41,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.pseudoRegret\"}}":{"definition":[252,4,252,16],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.regret\"}}":{"definition":[109,4,109,10],"usages":[[116,4,116,10,"FairnessLearning.regret_nonneg"],[117,9,117,15,"FairnessLearning.regret_nonneg"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.regret_nonneg\"}}":{"definition":[115,8,115,21],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.runAlgorithm\"}}":{"definition":[85,4,85,16],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.scalarizedLoss\"}}":{"definition":[321,4,321,18],"usages":[]},"{\"c\":{\"m\":\"Perspective.Proportionality\",\"n\":\"Proportionality.isProportional\"}}":{"definition":null,"usages":[[47,22,47,36]]},"{\"c\":{\"m\":\"Perspective.Proportionality\",\"n\":\"Proportionality.totalShortfall\"}}":{"definition":null,"usages":[[47,37,47,51],[160,2,160,16,"FairnessLearning.fairnessLoss"],[272,11,272,25,"FairnessLearning.fairnessConstraint"]]},"{\"c\":{\"m\":\"Perspective.Proportionality\",\"n\":\"Proportionality.total_shortfall_nonneg\"}}":{"definition":null,"usages":[[197,10,197,48,"FairnessLearning.fair_regret_nonneg"]]}},"version":5}