{"decls":{"FairnessLearning.Action":[58,0,61,31,61,4,61,10],"FairnessLearning.AdaptiveParams":[373,0,382,24,376,10,376,24],"FairnessLearning.BanditAlgorithm":[230,0,233,65,233,4,233,19],"FairnessLearning.BanditFeedback":[221,0,228,21,224,10,224,24],"FairnessLearning.Constraint":[290,0,293,41,293,4,293,14],"FairnessLearning.ExpWeightsParams":[148,0,155,15,151,10,151,26],"FairnessLearning.LearningReport":[401,0,412,25,402,10,402,24],"FairnessLearning.Loss":[63,0,66,16,66,7,66,11],"FairnessLearning.MultiObjective":[335,0,342,50,338,10,338,24],"FairnessLearning.OnlineAlgorithm":[77,0,80,64,80,4,80,19],"FairnessLearning.OnlineProblem":[68,0,75,47,71,10,71,23],"FairnessLearning.StochasticProblem":[259,0,266,19,262,10,262,27],"FairnessLearning.TimeHorizon":[53,0,56,20,56,4,56,15],"FairnessLearning.adagradLearningRate":[384,0,389,50,388,4,388,23],"FairnessLearning.adaptive_regret_bound":[391,0,397,45,395,6,395,27],"FairnessLearning.averageRegret":[120,0,124,38,123,4,123,17],"FairnessLearning.bandit_regret_lower_bound":[249,0,255,68,253,6,253,31],"FairnessLearning.bestFixedLoss":[98,0,104,3,101,4,101,17],"FairnessLearning.budgetConstraint":[295,0,299,30,298,4,298,20],"FairnessLearning.constrainedRegret":[307,0,311,28,310,4,310,21],"FairnessLearning.cumulativeLoss":[92,0,96,12,95,4,95,18],"FairnessLearning.epsilonGreedy":[242,0,247,45,245,4,245,17],"FairnessLearning.expWeightsUpdate":[157,0,162,48,160,4,160,20],"FairnessLearning.exp_weights_regret":[164,0,170,67,168,6,168,24],"FairnessLearning.explorationRate":[235,0,240,34,239,4,239,19],"FairnessLearning.fairRegret":[196,0,201,23,199,4,199,14],"FairnessLearning.fair_regret_nonneg":[203,0,217,48,206,8,206,26],"FairnessLearning.fairnessConstraint":[301,0,305,37,304,4,304,22],"FairnessLearning.fairnessLoss":[174,0,178,38,177,4,177,16],"FairnessLearning.fairnessOnlineProblem":[189,0,194,53,192,4,192,25],"FairnessLearning.fairness_loss_bounded":[180,0,187,56,186,6,186,27],"FairnessLearning.followTheLeader":[138,0,146,22,141,4,141,19],"FairnessLearning.generateLearningReport":[414,0,429,3,415,4,415,26],"FairnessLearning.learning_product":[433,0,454,72,445,8,445,24],"FairnessLearning.novelty_claim_learning":[456,0,473,9,470,8,470,30],"FairnessLearning.optimalStochasticAction":[268,0,273,16,271,4,271,27],"FairnessLearning.paretoRegret":[344,0,349,65,347,4,347,16],"FairnessLearning.projectOntoFeasible":[313,0,319,45,316,4,316,23],"FairnessLearning.projected_maintains_feasibility":[321,0,331,11,324,8,324,39],"FairnessLearning.pseudoRegret":[275,0,279,45,278,4,278,16],"FairnessLearning.regret":[106,0,110,20,109,4,109,10],"FairnessLearning.regret_nonneg":[112,0,118,10,115,8,115,21],"FairnessLearning.runAlgorithm":[82,0,88,4,85,4,85,16],"FairnessLearning.scalarizedLoss":[351,0,356,40,354,4,354,18],"FairnessLearning.scalarized_implies_pareto":[358,0,369,66,364,6,364,31],"FairnessLearning.stochastic_better_regret":[281,0,286,82,285,6,285,30],"FairnessLearning.sublinear_implies_vanishing":[126,0,134,64,132,6,132,33]},"directImports":[["Perspective.FairnessGames",false,false,false]],"module":"Perspective.FairnessLearning","references":{"{\"c\":{\"m\":\"Init.Data.List.Basic\",\"n\":\"List.sum\"}}":{"definition":null,"usages":[[96,9,96,12,"FairnessLearning.cumulativeLoss"]]},"{\"c\":{\"m\":\"Init.Data.List.Lemmas\",\"n\":\"List.mem_map\"}}":{"definition":null,"usages":[[211,6,211,18,"FairnessLearning.fair_regret_nonneg"]]},"{\"c\":{\"m\":\"Init.Data.NeZero\",\"n\":\"NeZero\"}}":{"definition":null,"usages":[[177,18,177,24,"FairnessLearning.fairnessLoss"],[186,29,186,35,"FairnessLearning.fairness_loss_bounded"],[192,27,192,33,"FairnessLearning.fairnessOnlineProblem"],[199,16,199,22,"FairnessLearning.fairRegret"],[206,28,206,34,"FairnessLearning.fair_regret_nonneg"],[304,24,304,30,"FairnessLearning.fairnessConstraint"],[445,26,445,32,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Init.Data.Rat.Basic\",\"n\":\"Rat\"}}":{"definition":null,"usages":[[61,30,61,31,"FairnessLearning.Action"],[66,15,66,16,"FairnessLearning.Loss"],[95,42,95,43,"FairnessLearning.cumulativeLoss"],[101,55,101,56,"FairnessLearning.bestFixedLoss"],[109,22,109,23,"FairnessLearning.regret"],[109,37,109,38,"FairnessLearning.regret"],[109,42,109,43,"FairnessLearning.regret"],[115,42,115,43,"FairnessLearning.regret_nonneg"],[123,33,123,34,"FairnessLearning.averageRegret"],[123,46,123,47,"FairnessLearning.averageRegret"],[132,53,132,54,"FairnessLearning.sublinear_implies_vanishing"],[133,35,133,36,"FairnessLearning.sublinear_implies_vanishing"],[153,6,153,7,"FairnessLearning.ExpWeightsParams"],[160,76,160,77,"FairnessLearning.expWeightsUpdate"],[161,22,161,23,"FairnessLearning.expWeightsUpdate"],[161,35,161,36,"FairnessLearning.expWeightsUpdate"],[169,10,169,11,"FairnessLearning.exp_weights_regret"],[170,65,170,66,"FairnessLearning.exp_weights_regret"],[177,52,177,53,"FairnessLearning.fairnessLoss"],[186,63,186,64,"FairnessLearning.fairness_loss_bounded"],[192,54,192,55,"FairnessLearning.fairnessOnlineProblem"],[199,67,199,68,"FairnessLearning.fairRegret"],[199,72,199,73,"FairnessLearning.fairRegret"],[206,79,206,80,"FairnessLearning.fair_regret_nonneg"],[216,14,216,15,"FairnessLearning.fair_regret_nonneg"],[239,30,239,31,"FairnessLearning.explorationRate"],[240,32,240,33,"FairnessLearning.explorationRate"],[245,23,245,24,"FairnessLearning.epsilonGreedy"],[255,61,255,62,"FairnessLearning.bandit_regret_lower_bound"],[264,28,264,29,"FairnessLearning.StochasticProblem"],[266,18,266,19,"FairnessLearning.StochasticProblem"],[278,56,278,57,"FairnessLearning.pseudoRegret"],[278,69,278,70,"FairnessLearning.pseudoRegret"],[286,59,286,60,"FairnessLearning.stochastic_better_regret"],[298,31,298,32,"FairnessLearning.budgetConstraint"],[304,43,304,44,"FairnessLearning.fairnessConstraint"],[304,51,304,52,"FairnessLearning.fairnessConstraint"],[310,50,310,51,"FairnessLearning.constrainedRegret"],[310,55,310,56,"FairnessLearning.constrainedRegret"],[342,49,342,50,"FairnessLearning.MultiObjective"],[348,28,348,29,"FairnessLearning.paretoRegret"],[354,79,354,80,"FairnessLearning.scalarizedLoss"],[355,21,355,22,"FairnessLearning.scalarizedLoss"],[365,39,365,40,"FairnessLearning.scalarized_implies_pareto"],[367,52,367,53,"FairnessLearning.scalarized_implies_pareto"],[378,7,378,8,"FairnessLearning.AdaptiveParams"],[380,6,380,7,"FairnessLearning.AdaptiveParams"],[388,73,388,74,"FairnessLearning.adagradLearningRate"],[388,78,388,79,"FairnessLearning.adagradLearningRate"],[396,23,396,24,"FairnessLearning.adaptive_regret_bound"],[397,10,397,11,"FairnessLearning.adaptive_regret_bound"],[406,21,406,22,"FairnessLearning.LearningReport"],[408,18,408,19,"FairnessLearning.LearningReport"],[415,53,415,54,"FairnessLearning.generateLearningReport"],[418,43,418,44,"FairnessLearning.generateLearningReport"],[445,77,445,78,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Init.Prelude\",\"n\":\"Bool\"}}":{"definition":null,"usages":[[246,15,246,19,"FairnessLearning.epsilonGreedy"],[410,16,410,20,"FairnessLearning.LearningReport"]]},"{\"c\":{\"m\":\"Init.Prelude\",\"n\":\"DecidablePred\"}}":{"definition":null,"usages":[[317,5,317,18,"FairnessLearning.projectOntoFeasible"],[325,5,325,18,"FairnessLearning.projected_maintains_feasibility"],[448,38,448,51,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Init.Prelude\",\"n\":\"Fin\"}}":{"definition":null,"usages":[[61,22,61,25,"FairnessLearning.Action"],[73,9,73,12,"FairnessLearning.OnlineProblem"],[160,68,160,71,"FairnessLearning.expWeightsUpdate"],[161,14,161,17,"FairnessLearning.expWeightsUpdate"],[161,27,161,30,"FairnessLearning.expWeightsUpdate"],[342,18,342,21,"FairnessLearning.MultiObjective"],[348,4,348,7,"FairnessLearning.paretoRegret"],[354,55,354,58,"FairnessLearning.scalarizedLoss"],[365,15,365,18,"FairnessLearning.scalarized_implies_pareto"]]},"{\"c\":{\"m\":\"Init.Prelude\",\"n\":\"List\"}}":{"definition":null,"usages":[[80,31,80,35,"FairnessLearning.OnlineAlgorithm"],[86,4,86,8,"FairnessLearning.runAlgorithm"],[95,29,95,33,"FairnessLearning.cumulativeLoss"],[141,31,141,35,"FairnessLearning.followTheLeader"],[199,41,199,45,"FairnessLearning.fairRegret"],[206,53,206,57,"FairnessLearning.fair_regret_nonneg"],[233,31,233,35,"FairnessLearning.BanditAlgorithm"],[347,57,347,61,"FairnessLearning.paretoRegret"],[367,19,367,23,"FairnessLearning.scalarized_implies_pareto"],[445,51,445,55,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Init.Prelude\",\"n\":\"List.map\"}}":{"definition":null,"usages":[[200,28,200,31,"FairnessLearning.fairRegret"],[349,39,349,42,"FairnessLearning.paretoRegret"],[368,44,368,47,"FairnessLearning.scalarized_implies_pareto"]]},"{\"c\":{\"m\":\"Init.Prelude\",\"n\":\"Max.max\"}}":{"definition":null,"usages":[[178,27,178,30,"FairnessLearning.fairnessLoss"],[217,13,217,16,"FairnessLearning.fair_regret_nonneg"]]},"{\"c\":{\"m\":\"Init.Prelude\",\"n\":\"Nat\"}}":{"definition":null,"usages":[[49,14,49,15],[56,19,56,20,"FairnessLearning.TimeHorizon"],[61,16,61,17,"FairnessLearning.Action"],[71,29,71,30,"FairnessLearning.OnlineProblem"],[71,37,71,38,"FairnessLearning.OnlineProblem"],[80,25,80,26,"FairnessLearning.OnlineAlgorithm"],[85,22,85,23,"FairnessLearning.runAlgorithm"],[101,23,101,24,"FairnessLearning.bestFixedLoss"],[123,41,123,42,"FairnessLearning.averageRegret"],[132,49,132,50,"FairnessLearning.sublinear_implies_vanishing"],[160,26,160,27,"FairnessLearning.expWeightsUpdate"],[168,58,168,59,"FairnessLearning.exp_weights_regret"],[192,42,192,43,"FairnessLearning.fairnessOnlineProblem"],[224,30,224,31,"FairnessLearning.BanditFeedback"],[233,25,233,26,"FairnessLearning.BanditAlgorithm"],[239,25,239,26,"FairnessLearning.explorationRate"],[253,37,253,38,"FairnessLearning.bandit_regret_lower_bound"],[262,33,262,34,"FairnessLearning.StochasticProblem"],[278,64,278,65,"FairnessLearning.pseudoRegret"],[285,65,285,66,"FairnessLearning.stochastic_better_regret"],[293,20,293,21,"FairnessLearning.Constraint"],[338,30,338,31,"FairnessLearning.MultiObjective"],[340,18,340,19,"FairnessLearning.MultiObjective"],[395,59,395,60,"FairnessLearning.adaptive_regret_bound"],[404,11,404,12,"FairnessLearning.LearningReport"],[415,37,415,38,"FairnessLearning.generateLearningReport"]]},"{\"c\":{\"m\":\"Init.Prelude\",\"n\":\"String\"}}":{"definition":null,"usages":[[412,19,412,25,"FairnessLearning.LearningReport"]]},"{\"c\":{\"m\":\"Init.Prelude\",\"n\":\"True\"}}":{"definition":null,"usages":[[472,4,472,8,"FairnessLearning.novelty_claim_learning"]]},"{\"c\":{\"m\":\"Mathlib.Algebra.Order.BigOperators.Group.List\",\"n\":\"List.sum_nonneg\"}}":{"definition":null,"usages":[[209,8,209,23,"FairnessLearning.fair_regret_nonneg"]]},"{\"c\":{\"m\":\"Mathlib.Algebra.Order.GroupWithZero.Unbundled.Basic\",\"n\":\"div_nonneg\"}}":{"definition":null,"usages":[[214,8,214,18,"FairnessLearning.fair_regret_nonneg"]]},"{\"c\":{\"m\":\"Mathlib.Order.Defs.LinearOrder\",\"n\":\"le_max_right\"}}":{"definition":null,"usages":[[217,28,217,40,"FairnessLearning.fair_regret_nonneg"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.Action\"}}":{"definition":[61,4,61,10],"usages":[[73,17,73,23,"FairnessLearning.OnlineProblem"],[80,37,80,43,"FairnessLearning.OnlineAlgorithm"],[80,56,80,62,"FairnessLearning.OnlineAlgorithm"],[86,10,86,16,"FairnessLearning.runAlgorithm"],[141,37,141,43,"FairnessLearning.followTheLeader"],[141,72,141,78,"FairnessLearning.followTheLeader"],[141,84,141,90,"FairnessLearning.followTheLeader"],[177,33,177,39,"FairnessLearning.fairnessLoss"],[186,44,186,50,"FairnessLearning.fairness_loss_bounded"],[199,47,199,53,"FairnessLearning.fairRegret"],[206,59,206,65,"FairnessLearning.fair_regret_nonneg"],[226,11,226,17,"FairnessLearning.BanditFeedback"],[233,57,233,63,"FairnessLearning.BanditAlgorithm"],[245,39,245,45,"FairnessLearning.epsilonGreedy"],[245,65,245,71,"FairnessLearning.epsilonGreedy"],[246,23,246,29,"FairnessLearning.epsilonGreedy"],[264,17,264,23,"FairnessLearning.StochasticProblem"],[271,59,271,65,"FairnessLearning.optimalStochasticAction"],[293,26,293,32,"FairnessLearning.Constraint"],[316,29,316,35,"FairnessLearning.projectOntoFeasible"],[318,23,318,29,"FairnessLearning.projectOntoFeasible"],[318,35,318,41,"FairnessLearning.projectOntoFeasible"],[324,45,324,51,"FairnessLearning.projected_maintains_feasibility"],[326,23,326,29,"FairnessLearning.projected_maintains_feasibility"],[342,38,342,44,"FairnessLearning.MultiObjective"],[347,63,347,69,"FairnessLearning.paretoRegret"],[355,9,355,15,"FairnessLearning.scalarizedLoss"],[367,25,367,31,"FairnessLearning.scalarized_implies_pareto"],[445,57,445,63,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.AdaptiveParams\"}}":{"definition":[376,10,376,24,"FairnessLearning.AdaptiveParams"],"usages":[[388,34,388,48,"FairnessLearning.adagradLearningRate"],[395,38,395,52,"FairnessLearning.adaptive_regret_bound"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.AdaptiveParams.valid\"}}":{"definition":[382,2,382,7],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.AdaptiveParams.α\"}}":{"definition":[380,2,380,3],"usages":[[389,26,389,27,"FairnessLearning.adagradLearningRate"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.AdaptiveParams.η₀\"}}":{"definition":[378,2,378,4],"usages":[[389,9,389,11,"FairnessLearning.adagradLearningRate"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.BanditAlgorithm\"}}":{"definition":[233,4,233,19],"usages":[[254,13,254,28,"FairnessLearning.bandit_regret_lower_bound"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.BanditFeedback\"}}":{"definition":[224,10,224,24,"FairnessLearning.BanditFeedback"],"usages":[[233,37,233,51,"FairnessLearning.BanditAlgorithm"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.BanditFeedback.action\"}}":{"definition":[226,2,226,8],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.BanditFeedback.observedLoss\"}}":{"definition":[228,2,228,14],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.Constraint\"}}":{"definition":[293,4,293,14],"usages":[[298,36,298,46,"FairnessLearning.budgetConstraint"],[304,56,304,66,"FairnessLearning.fairnessConstraint"],[316,53,316,63,"FairnessLearning.projectOntoFeasible"],[324,69,324,79,"FairnessLearning.projected_maintains_feasibility"],[448,23,448,33,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.ExpWeightsParams\"}}":{"definition":[151,10,151,26,"FairnessLearning.ExpWeightsParams"],"usages":[[160,39,160,55,"FairnessLearning.expWeightsUpdate"],[168,35,168,51,"FairnessLearning.exp_weights_regret"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.ExpWeightsParams.η\"}}":{"definition":[153,2,153,3],"usages":[[162,35,162,36,"FairnessLearning.expWeightsUpdate"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.ExpWeightsParams.η_pos\"}}":{"definition":[155,2,155,7],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.LearningReport\"}}":{"definition":[402,10,402,24,"FairnessLearning.LearningReport"],"usages":[[415,58,415,72,"FairnessLearning.generateLearningReport"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.LearningReport.averageRegret\"}}":{"definition":[408,2,408,15],"usages":[[426,4,426,17,"FairnessLearning.generateLearningReport"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.LearningReport.cumulativeRegret\"}}":{"definition":[406,2,406,18],"usages":[[425,4,425,20,"FairnessLearning.generateLearningReport"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.LearningReport.isSublinear\"}}":{"definition":[410,2,410,13],"usages":[[427,4,427,15,"FairnessLearning.generateLearningReport"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.LearningReport.recommendation\"}}":{"definition":[412,2,412,16],"usages":[[428,4,428,18,"FairnessLearning.generateLearningReport"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.LearningReport.rounds\"}}":{"definition":[404,2,404,8],"usages":[[424,4,424,10,"FairnessLearning.generateLearningReport"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.Loss\"}}":{"definition":[66,7,66,11],"usages":[[73,28,73,32,"FairnessLearning.OnlineProblem"],[80,48,80,52,"FairnessLearning.OnlineAlgorithm"],[86,21,86,25,"FairnessLearning.runAlgorithm"],[95,34,95,38,"FairnessLearning.cumulativeLoss"],[141,48,141,52,"FairnessLearning.followTheLeader"],[177,57,177,61,"FairnessLearning.fairnessLoss"],[228,17,228,21,"FairnessLearning.BanditFeedback"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.MultiObjective\"}}":{"definition":[338,10,338,24,"FairnessLearning.MultiObjective"],"usages":[[347,24,347,38,"FairnessLearning.paretoRegret"],[354,26,354,40,"FairnessLearning.scalarizedLoss"],[364,39,364,53,"FairnessLearning.scalarized_implies_pareto"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.MultiObjective.numObjectives\"}}":{"definition":[340,2,340,15],"usages":[[348,12,348,25,"FairnessLearning.paretoRegret"],[354,63,354,76,"FairnessLearning.scalarizedLoss"],[365,23,365,36,"FairnessLearning.scalarized_implies_pareto"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.MultiObjective.objectiveLoss\"}}":{"definition":[342,2,342,15],"usages":[[349,48,349,61,"FairnessLearning.paretoRegret"],[356,23,356,36,"FairnessLearning.scalarizedLoss"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.OnlineAlgorithm\"}}":{"definition":[80,4,80,19],"usages":[[85,32,85,47,"FairnessLearning.runAlgorithm"],[286,13,286,28,"FairnessLearning.stochastic_better_regret"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.OnlineProblem\"}}":{"definition":[71,10,71,23,"FairnessLearning.OnlineProblem"],"usages":[[85,59,85,72,"FairnessLearning.runAlgorithm"],[101,34,101,47,"FairnessLearning.bestFixedLoss"],[169,31,169,44,"FairnessLearning.exp_weights_regret"],[192,59,192,72,"FairnessLearning.fairnessOnlineProblem"],[254,43,254,56,"FairnessLearning.bandit_regret_lower_bound"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.OnlineProblem.bounded\"}}":{"definition":[75,2,75,9],"usages":[[194,2,194,9,"FairnessLearning.fairnessOnlineProblem"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.OnlineProblem.loss\"}}":{"definition":[73,2,73,6],"usages":[[193,2,193,6,"FairnessLearning.fairnessOnlineProblem"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.StochasticProblem\"}}":{"definition":[262,10,262,27,"FairnessLearning.StochasticProblem"],"usages":[[271,36,271,53,"FairnessLearning.optimalStochasticAction"],[285,39,285,56,"FairnessLearning.stochastic_better_regret"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.StochasticProblem.expectedLoss\"}}":{"definition":[264,2,264,14],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.StochasticProblem.varianceBound\"}}":{"definition":[266,2,266,15],"usages":[[286,69,286,82,"FairnessLearning.stochastic_better_regret"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.TimeHorizon\"}}":{"definition":[56,4,56,15],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.adagradLearningRate\"}}":{"definition":[388,4,388,23],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.adaptive_regret_bound\"}}":{"definition":[395,6,395,27,"FairnessLearning.adaptive_regret_bound"],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.averageRegret\"}}":{"definition":[123,4,123,17],"usages":[[134,29,134,42,"FairnessLearning.sublinear_implies_vanishing"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.bandit_regret_lower_bound\"}}":{"definition":[253,6,253,31,"FairnessLearning.bandit_regret_lower_bound"],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.bestFixedLoss\"}}":{"definition":[101,4,101,17],"usages":[[170,34,170,47,"FairnessLearning.exp_weights_regret"],[255,34,255,47,"FairnessLearning.bandit_regret_lower_bound"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.budgetConstraint\"}}":{"definition":[298,4,298,20],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.constrainedRegret\"}}":{"definition":[310,4,310,21],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.cumulativeLoss\"}}":{"definition":[95,4,95,18],"usages":[[170,14,170,28,"FairnessLearning.exp_weights_regret"],[201,2,201,16,"FairnessLearning.fairRegret"],[208,20,208,34,"FairnessLearning.fair_regret_nonneg"],[255,14,255,28,"FairnessLearning.bandit_regret_lower_bound"],[349,11,349,25,"FairnessLearning.paretoRegret"],[368,16,368,30,"FairnessLearning.scalarized_implies_pareto"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.epsilonGreedy\"}}":{"definition":[245,4,245,17],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.expWeightsUpdate\"}}":{"definition":[160,4,160,20],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.exp_weights_regret\"}}":{"definition":[168,6,168,24,"FairnessLearning.exp_weights_regret"],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.explorationRate\"}}":{"definition":[239,4,239,19],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.fairRegret\"}}":{"definition":[199,4,199,14],"usages":[[207,4,207,14,"FairnessLearning.fair_regret_nonneg"],[208,9,208,19,"FairnessLearning.fair_regret_nonneg"],[447,5,447,15,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.fair_regret_nonneg\"}}":{"definition":[206,8,206,26],"usages":[[452,10,452,28,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.fairnessConstraint\"}}":{"definition":[304,4,304,22],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.fairnessLoss\"}}":{"definition":[177,4,177,16],"usages":[[187,9,187,21,"FairnessLearning.fairness_loss_bounded"],[187,32,187,44,"FairnessLearning.fairness_loss_bounded"],[193,21,193,33,"FairnessLearning.fairnessOnlineProblem"],[200,42,200,54,"FairnessLearning.fairRegret"],[213,9,213,21,"FairnessLearning.fair_regret_nonneg"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.fairnessOnlineProblem\"}}":{"definition":[192,4,192,25],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.fairness_loss_bounded\"}}":{"definition":[186,6,186,27,"FairnessLearning.fairness_loss_bounded"],"usages":[[194,24,194,45,"FairnessLearning.fairnessOnlineProblem"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.followTheLeader\"}}":{"definition":[141,4,141,19],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.generateLearningReport\"}}":{"definition":[415,4,415,26],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.learning_product\"}}":{"definition":[445,8,445,24],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.novelty_claim_learning\"}}":{"definition":[470,8,470,30],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.optimalStochasticAction\"}}":{"definition":[271,4,271,27],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.paretoRegret\"}}":{"definition":[347,4,347,16],"usages":[[369,9,369,21,"FairnessLearning.scalarized_implies_pareto"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.projectOntoFeasible\"}}":{"definition":[316,4,316,23],"usages":[[327,16,327,35,"FairnessLearning.projected_maintains_feasibility"],[328,9,328,28,"FairnessLearning.projected_maintains_feasibility"],[450,18,450,37,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.projected_maintains_feasibility\"}}":{"definition":[324,8,324,39],"usages":[[454,10,454,41,"FairnessLearning.learning_product"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.pseudoRegret\"}}":{"definition":[278,4,278,16],"usages":[[286,33,286,45,"FairnessLearning.stochastic_better_regret"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.regret\"}}":{"definition":[109,4,109,10],"usages":[[116,4,116,10,"FairnessLearning.regret_nonneg"],[117,9,117,15,"FairnessLearning.regret_nonneg"],[170,6,170,12,"FairnessLearning.exp_weights_regret"],[255,6,255,12,"FairnessLearning.bandit_regret_lower_bound"],[397,13,397,19,"FairnessLearning.adaptive_regret_bound"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.regret_nonneg\"}}":{"definition":[115,8,115,21],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.runAlgorithm\"}}":{"definition":[85,4,85,16],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.scalarizedLoss\"}}":{"definition":[354,4,354,18],"usages":[[368,49,368,63,"FairnessLearning.scalarized_implies_pareto"]]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.scalarized_implies_pareto\"}}":{"definition":[364,6,364,31,"FairnessLearning.scalarized_implies_pareto"],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.stochastic_better_regret\"}}":{"definition":[285,6,285,30,"FairnessLearning.stochastic_better_regret"],"usages":[]},"{\"c\":{\"m\":\"Perspective.FairnessLearning\",\"n\":\"FairnessLearning.sublinear_implies_vanishing\"}}":{"definition":[132,6,132,33,"FairnessLearning.sublinear_implies_vanishing"],"usages":[]},"{\"c\":{\"m\":\"Perspective.Proportionality\",\"n\":\"Proportionality.isProportional\"}}":{"definition":null,"usages":[[47,22,47,36]]},"{\"c\":{\"m\":\"Perspective.Proportionality\",\"n\":\"Proportionality.totalShortfall\"}}":{"definition":null,"usages":[[47,37,47,51],[178,2,178,16,"FairnessLearning.fairnessLoss"],[305,11,305,25,"FairnessLearning.fairnessConstraint"]]},"{\"c\":{\"m\":\"Perspective.Proportionality\",\"n\":\"Proportionality.total_shortfall_nonneg\"}}":{"definition":null,"usages":[[215,10,215,48,"FairnessLearning.fair_regret_nonneg"]]}},"version":5}